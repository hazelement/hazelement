{"pages":[{"url":"https://hazelement.github.io/pages/about.html","text":"I used to be a mechanical engineer who worked in the oil and gas industry. The downturn of the oil price has driven thousands of people out of employment and I am one of them. But with my great interest and experience in programming, I started working at a software developer at a startup IT company. The world is brand new to me and I'm learning great things everyday. Then one day I decided that I should start tracking down my learning progress. It could be useful for my own personal reference and also benefit people who is or will be taking a similar path to become a programmer. Hence I started this blog, Nov 19, 2016.","tags":"pages","title":"About"},{"url":"https://hazelement.github.io/pages/contact.html","text":"Feel free to leave me a comment or contact me through my github profile.","tags":"pages","title":"Contact"},{"url":"https://hazelement.github.io/pages/markdownsample.html","text":"This is the content of my super blog post.","tags":"pages","title":"MarkDownSample"},{"url":"https://hazelement.github.io/pages/rstsample.html","text":"This is another post from rst file.","tags":"example","title":"RSTSample"},{"url":"https://hazelement.github.io/kubernetes-basics.html","text":"This article covers some basic commands and instructions to deploy a kubernetes app. Some notes and images are taken from https://kubernetes.io/docs/tutorials . Basic concept Nodes A kubernetes cluster is consist of Nodes . A node can be a VM or a physical machine. To check current nodes issue this command: $ kubectl get nodes NAME STATUS ROLES AGE VERSION docker-for-desktop Ready master 30m v1.10.11 Each cluster should have one master node with a 0 or a few slave nodes. Pods A node is consists of one or more Pods . To get list of running pods, issue this command: $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5c69669756-rmxrn 1 /1 Running 0 45m A Pod is a Kubernetes abstraction that represents a group of one or more application containers (such as Docker or rkt), and some shared resources for those containers. Those resources include: Shared storage, as Volumes Networking, as a unique cluster IP address Information about how to run each container, such as the container image version or specific ports to use Services A Service in Kubernetes is an abstraction which defines a logical set of Pods and a policy by which to access them. Services enable a loose coupling between dependent Pods. A Service is defined using YAML (preferred) or JSON, like all Kubernetes objects. A Service routes traffic across a set of Pods. Services are the abstraction that allow pods to die and replicate in Kubernetes without impacting your application. Discovery and routing among dependent Pods (such as the frontend and backend components in an application) is handled by Kubernetes Services. Services match a set of Pods using labels and selectors, a grouping primitive that allows logical operation on objects in Kubernetes. Labels are key/value pairs attached to objects and can be used in any number of ways: Designate objects for development, test, and production Embed version tags Classify an object using tags Networking Pods running in side Kubernetes are running on a prviate, isolated network. By default, they are visible from other pods and services within the same cluster, but not outside. To quickly open on communication to outside world, kubectl can create a proxy to foward communications, kubectl proxy will create a proxy at http://localhost:8001/version . The API server will automatically create an endpoint for each pod, based on the pod name, that is also accessible through the proxy. To access each individual pod, we need to get pod name. export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}') . Then we can make a HTTP request to the application in that pod. curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/ Tutorial Make an deployment Run this commmand to make a new deployment. kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 Get the name of running pod, export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}') . Check application configuration Let's verify that the application we deployed in the previous scenario is running. We'll use the kubectl get command and look for existing Pods: $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5c69669756-rmxrn 1 /1 Running 0 1h Next, to view what containers are inside that Pod and what images are used to build those containers we run the describe pods command: kubectl describe pods . View container logs Anything that the application would normally send to STDOUT becomes logs for the container within the Pod. We can retrieve these logs using the kubectl logs command: kubectl logs $POD_NAME Note: We don't need to specify the container name, because we only have one container inside the pod. Executing command on the container We can execute commands directly on the container once the Pod is up and running. For this, we use the exec command and use the name of the Pod as a parameter. Let's list the environment variables: $ kubectl exec $POD_NAME env PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME = kubernetes-bootcamp-5c69669756-rmxrn KUBERNETES_PORT = tcp://10.96.0.1:443 KUBERNETES_PORT_443_TCP = tcp://10.96.0.1:443 KUBERNETES_PORT_443_TCP_PROTO = tcp KUBERNETES_PORT_443_TCP_PORT = 443 KUBERNETES_PORT_443_TCP_ADDR = 10 .96.0.1 KUBERNETES_SERVICE_HOST = 10 .96.0.1 KUBERNETES_SERVICE_PORT = 443 KUBERNETES_SERVICE_PORT_HTTPS = 443 NPM_CONFIG_LOGLEVEL = info NODE_VERSION = 6 .3.1 HOME = /root Again, worth mentioning that the name of the container itself can be omitted since we only have a single container in the Pod. Next let's start a bash session in the Pod's container: kubectl exec -ti $POD_NAME bash . We have now an open console on the container. To close the console, use exit . Create a new service To list current services in the cluster: $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 1h Cluter services is created by default. To create a new service using running pods: kubectl expose deployment/kubernetes-bootcamp --type=\"NodePort\" --port 8080 List services again: $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 1h kubernetes-bootcamp NodePort 10 .104.156.85 <none> 8080 :30527/TCP 2s Notice that the new service kubernetes-bootcamp has a unique cluster-IP 10.104.156.85 , an internal port 30527 and an external port 8080 . Try access the end point with curl 10.104.156.85:8080 . Using labels The Deployment created automatically a label for our Pod. With describe deployment command you can see the name of the label: kubectl describe deployment . This label can be used to query list of Pods: $ kubectl get pods -l run = kubernetes-bootcamp NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5c69669756-rmxrn 1 /1 Running 0 1h The same can be used on services: $ kubectl get services -l run = kubernetes-bootcamp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes-bootcamp NodePort 10 .104.156.85 <none> 8080 :30527/TCP 24m Get name of the pod: export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}') Apply a new label to this pod: kubectl label pod $POD_NAME app=v1 And check the pod description: $ kubectl describe pods $ POD_NAME ` Name : kubernetes - bootcamp - 5 c69669756 - rmxrn Namespace : default Node : docker - for - desktop / 192.168 . 65.3 Start Time : Thu , 21 Feb 2019 14 : 51 : 05 - 0700 Labels : app = v1 pod - template - hash = 1725225312 run = kubernetes - bootcamp ... This label can be used to query pods: $ kubectl get pods -l app = v1 NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5c69669756-rmxrn 1 /1 Running 0 1h Delete a service To delete a service, use this command kubectl delete service -l run=kubernetes-bootcamp Confirm the service is gone: $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 2h But the pod should still be running: $ kubectl exec -ti $POD_NAME curl localhost:8080 Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-5c69669756-rmxrn | v = 1 Scaling a service Scaling is achieved through number of replica in a deployment. Kubernetes also support auto scaling but it's not covered in this part of the tutorial. Running multiple instances of an application will require a way to distribute the traffic to all of them. Services have an integrated load-balancer that will distribute network traffic to all Pods of an exposed Deployment. Services will monitor continuously the running Pods using endpoints, to ensure the traffic is sent only to available Pods. Once you have multiple instances of an Application running, you would be able to do Rolling updates without downtime. To scale an existing service, use the following commands. List running deployments: $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 1 /1 1 1 37s The DESIRED state is showing the configured number of replicas. The CURRENT state show how many replicas are running now. The UP-TO-DATE is the number of replicas that were updated to match the desired (configured) state. To scale the deployments to replica of 4: $ kubectl scale deployments/kubernetes-bootcamp --replicas = 4 deployment.apps/kubernetes-bootcamp scaled $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 4 /4 4 4 100s We can see the available instances and ready instances are now four. Check if number of pods changed: $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kubernetes-bootcamp-6bf84cb898-4jx92 1 /1 Running 0 8s 172 .18.0.7 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-mm2g5 1 /1 Running 0 8s 172 .18.0.5 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-rsml8 1 /1 Running 0 8s 172 .18.0.3 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-wfvkt 1 /1 Running 0 8s 172 .18.0.6 minikube <none> <none> There are 4 pods with different IP now. The changes should also register with deployments. $ kubectl describe deployments / kubernetes - bootcamp Name : kubernetes - bootcamp Namespace : default CreationTimestamp : Sat , 23 Feb 2019 17 : 38 : 57 + 0000 Labels : run = kubernetes - bootcamp Annotations : deployment . kubernetes . io / revision : 1 Selector : run = kubernetes - bootcamp Replicas : 4 desired | 4 updated | 4 total | 4 available | 0 unavailable StrategyType : RollingUpdate MinReadySeconds : 0 RollingUpdateStrategy : 25 % max unavailable , 25 % max surge Pod Template : Labels : run = kubernetes - bootcamp Containers : kubernetes - bootcamp : Image : gcr . io / google - samples / kubernetes - bootcamp : v1 Port : 8080 / TCP Host Port : 0 / TCP Environment : < none > Mounts : < none > Volumes : < none > Conditions : Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets : < none > NewReplicaSet : kubernetes - bootcamp - 6 bf84cb898 ( 4 / 4 replicas created ) Events : Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 73s deployment - controller Scaled up replicaset kubernetes - bootcamp - 6 bf84cb898 to 4 Load balancing With replica enabled, load balancing should also automatically enable for this service. $ kubectl describe services / kubernetes - bootcamp Name : kubernetes - bootcamp Namespace : default Labels : run = kubernetes - bootcamp Annotations : < none > Selector : run = kubernetes - bootcamp Type : NodePort IP : 10.97 . 18.242 Port : < unset > 8080 / TCP TargetPort : 8080 / TCP NodePort : < unset > 32111 / TCP Endpoints : 172.18 . 0.3 : 8080 , 172.18 . 0.5 : 8080 , 172.18 . 0.6 : 8080 + 1 more ... Session Affinity : None External Traffic Policy : Cluster Events : < none > There are 4 endpoints on this services, each one is one our the replica. To verify the load balancing is working. Let's make request to this service and each time we should be hitting different pods. $ export NODE_PORT = $( kubectl get services/kubernetes-bootcamp -o go-template = '{{(index .spec.ports 0).nodePort}}' ) $ echo NODE_PORT = $NODE_PORT NODE_PORT = 32111 $ curl $( minikube ip ) : $NODE_PORT Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-6bf84cb898-rsml8 | v = 1 $ curl $( minikube ip ) : $NODE_PORT Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-6bf84cb898-4jx92 | v = 1 $ curl $( minikube ip ) : $NODE_PORT Hello Kubernetes bootcamp! | Running on: kubernetes-bootcamp-6bf84cb898-wfvkt | v = 1 As we can see in the curl printout. Each time we hit a different pod. Scale down To scale down the service, issue the same scale command but with a smaller replica number. $ kubectl scale deployments/kubernetes-bootcamp --replicas = 2 deployment.extensions/kubernetes-bootcamp scaled $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 2 /2 2 2 6m26s $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kubernetes-bootcamp-6bf84cb898-4jx92 1 /1 Terminating 0 6m18s 172 .18.0.7 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-mm2g5 1 /1 Running 0 6m18s 172 .18.0.5 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-rsml8 1 /1 Running 0 6m18s 172 .18.0.3 minikube <none> <none> kubernetes-bootcamp-6bf84cb898-wfvkt 1 /1 Terminating 0 6m18s 172 .18.0.6 minikube <none> <none> This confirms that 2 pods are terminating. Rolling updates Rolling updates allow Deployments' update to take place with zero downtime by incrementally updating Pods instances with new ones. The new Pods will be scheduled on Nodes with available resources. By default, the maximum number of Pods that can be unavailable during the update and the maximum number of new Pods that can be created, is one. Both options can be configured to either numbers or percentages (of Pods). In Kubernetes, updates are versioned and any Deployments update can be rolled back to previous (stable) version. Similar to application Scaling, if a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update. An available Pod is an instance that is available to the users of the application. Rolling updates allow the following actions: Promote an application from one environment to another (via container image updates) Rollback to previous versions Continuous Integration and Continuous Delivery of applications with zero downtime To roll out an update, follow these steps: List running deployments: $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 4 /4 4 4 24s List running pods: $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-6bf84cb898-dg8zx 1 /1 Running 0 25s kubernetes-bootcamp-6bf84cb898-fzb22 1 /1 Running 0 25s kubernetes-bootcamp-6bf84cb898-mfq7l 1 /1 Running 0 25s kubernetes-bootcamp-6bf84cb898-r8snq 1 /1 Running 0 25s To update the image of the application to version 2, use the set image command, followed by the deployment name and the new image version: $ kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp = jocatalin/kubernetes-bootcamp:v2 deployment.apps/kubernetes-bootcamp image updated The command notified the Deployment to use a different image for your app and initiated a rolling update. Check the status of the new Pods, and view the old one terminating with the get pods command: $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5bf4d5689b-4xkmn 1 /1 Running 0 10s kubernetes-bootcamp-5bf4d5689b-hv6qr 1 /1 Running 0 10s kubernetes-bootcamp-5bf4d5689b-jm57j 1 /1 Running 0 13s kubernetes-bootcamp-5bf4d5689b-qvgkz 1 /1 Running 0 13s kubernetes-bootcamp-6bf84cb898-dg8zx 1 /1 Terminating 0 83s kubernetes-bootcamp-6bf84cb898-fzb22 1 /1 Terminating 0 83s kubernetes-bootcamp-6bf84cb898-mfq7l 1 /1 Terminating 0 83s kubernetes-bootcamp-6bf84cb898-r8snq 1 /1 Terminating 0 83s $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5bf4d5689b-4xkmn 1 /1 Running 0 43s kubernetes-bootcamp-5bf4d5689b-hv6qr 1 /1 Running 0 43s kubernetes-bootcamp-5bf4d5689b-jm57j 1 /1 Running 0 46s kubernetes-bootcamp-5bf4d5689b-qvgkz 1 /1 Running 0 46s Old instances are replaced with updated instances eventually. The update can be confirmed also by running a rollout status command: $ kubectl rollout status deployments/kubernetes-bootcamp deployment \"kubernetes-bootcamp\" successfully rolled out To view the current image version of the app, run a describe command against the Pods: kubectl describe pods To roll back an update, let's deploy an update with problems: kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=gcr.io/google-samples/kubernetes-bootcamp:v10 And check status: $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 3 /4 2 3 5m29s $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-597cfc5b76-cxccd 0 /1 ImagePullBackOff 0 69s kubernetes-bootcamp-597cfc5b76-h6r48 0 /1 ErrImagePull 0 69s kubernetes-bootcamp-5bf4d5689b-4xkmn 1 /1 Running 0 4m9s kubernetes-bootcamp-5bf4d5689b-jm57j 1 /1 Running 0 4m12s kubernetes-bootcamp-5bf4d5689b-qvgkz 1 /1 Running 0 4m12s Something is wrong with the updated images. To get more insights, use the describe command: kubectl describe pods To roll back the update, issue this command: $ kubectl rollout undo deployments/kubernetes-bootcamp deployment.apps/kubernetes-bootcamp rolled back And we are back to old state: $ kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-5bf4d5689b-4xkmn 1 /1 Running 0 5m41s kubernetes-bootcamp-5bf4d5689b-j6kp4 1 /1 Running 0 21s kubernetes-bootcamp-5bf4d5689b-jm57j 1 /1 Running 0 5m44s kubernetes-bootcamp-5bf4d5689b-qvgkz 1 /1 Running 0 5m44s Kubernetes Commands check current version: kubectl version get cluster info: kubectl cluster-info list nodes: kubectl get nodes list pods: kubectl get pods describe pods: kubectl describe pods run a deployment: kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 list deployments: kubectl get deployments","tags":"Kubernetes","title":"Kubernetes Basics"},{"url":"https://hazelement.github.io/compile-tcpdump-for-android.html","text":"There are many ways to sniff network traffic on android, VPN, proxy and etc. Today we are gonna look into using compiling tcpdump for Android which can be used with netcat to sniff network traffic later. The Linux binaries We will be using two Linux binaries to achive this, tcpdump and netcat. Tcpdump is a popular tool in Linux to capture net traffic. Netcat is another Linux binary that are commonly used to listen on a socket. We will be using these two binaries along with Java coded android apps to demonstrate the technique. A Rooted Android Phone First thing first, this technique requires a rooted android phone. If your phone is not rooted, check out some posts and root your device first. Compile Tcpdump and Netcat Binaries for Android Like any other binaries written in C, we need to compile them differerntly if we want to run them on differernt platforms. Let's start by installing our android compiler, assuming we are compiling for arm processor architecture. Execute the following command in your Ubuntu shell. sudo apt-get install gcc-arm-linux-gnueabi sudo apt-get install byacc sudo apt-get install flex This will install gcc for arm architectre and other support tools for compiling. Next, create a folder named \"compile_for_android\", this is where we will be performing all the compiling. mkdir compile_for_android cd compile_for_android Now let's download tcpdump source code. wget http://www.tcpdump.org/release/tcpdump-4.8.1.tar.gz Tcpdump depends on libpcap, so we need to download and compile libpcap source code as well. wget http://www.tcpdump.org/release/libpcap-1.8.1.tar.gz Extract these two packages. tar zxvf tcpdump-4.8.1.tar.gz tar zxvf libpcap-1.8.1.tar.gz Now we are ready to compile our tcpdump. First, let's make sure our compiler is the android compiler. export CC = arm-linux-gnueabi-gcc Compiler libpcap first. cd libpcap-1.8.1 ./configure --host = arm-linux --with-pcap = linux make This should compiler the libpcap library for us. Now let's go to our tcpdump directory. cd .. cd tcpdump-4.8.1 Before we perform the same thing above, there is a few things we need to do. Figure out what major version our Ubuntu we have, uname -a This will give out something like this. 4 .2.0-42-generic In this case, our major version is 4 and we set a variable in command. export ac_cs_linux_vers = 4 Set the following variables to make our binary self contained (ie. not reliant on other libraries). export CFLAGS = -static export CPPFLAGS = -static export LDFLAGS = -static And configure the directory, ./configure --host = arm-linux --disable-ipv6 And then make it, make Strip the symbol information to make binary smaller. These symbols are only useful in debugging the application. arm-linux-gnueabi-strip tcpdump","tags":"Android","title":"Compile tcpdump for android."},{"url":"https://hazelement.github.io/setup-jenkins-with-django-for-continous-deployment.html","text":"About Jenkins Jenkins is a tool that is widely used for continous integration/deployment. It's basically a tool to automate the process of writing code, running tests and deploy for production. We will be using this post to demonstrate the setup using a \"hello world\" Django web application. The web application will be served using apache. However, the setup can be used with any web development language and framework. The Setup Our development code will be sitting at ~/django_hello_world. For simplicity, the source code will be pushed to a git repository that is sitting on the same machine at /webapp_repo. It can be on other machine through a ssh tunnel. The production code, which is also our live code, will be sitting at /webapps/django_hello_world Django Hello World First thing first, we need to setup an web application first. This will be a similar version of the official Django tutorial, https://docs.djangoproject.com/en/1.10/intro/tutorial01/ . Start the Django project: cd ~/django_hello_world django-admin startproject hello_world Under the same directory, create an app called polls: python manage.py startapp polls This will create a folder called polls. Under polls, open up the file called views and put the following code: from django.http import HttpResponse def index ( request ): return HttpResponse ( \"Hello, world. You're at the polls index.\" ) In the same polls folder, create a file named \"urls.py\" which will define the urls. In the urls file, enter the following code: from django.conf.urls import url from . import views urlpatterns = [ url ( r '&#94;$' , views . index , name = 'index' ), ] Now let's link this url file to the global url file. Open up the urls.py file under hello world folder and put in the following code: from django.conf.urls import url , include from django.contrib import admin urlpatterns = [ url ( r '&#94;polls/' , include ( 'polls.urls' )), url ( r '&#94;admin/' , admin . site . urls ), ] And that's it! Go back to project root directory: cd ~/django_hello_world And run this command: python manage.py runserver Open up http://localhost:8000/polls/ in the browser and we should see the text \"Hello, world. You're at the polls index.\" Remember this only runs our web application under local host, and only we can see it. In order for other people to see it, we need to use apache to serve it. Serve Django with Apache Django's tutorial website has a thorough documentation on the setup, https://docs.djangoproject.com/en/1.10/howto/deployment/wsgi/modwsgi/ . We will briefly mention it here. Using mod_wsgi daemon mode is the recommended way to serve our application. Assuming we have apache and mod_wsgi installed. First of all, let's create a directory to store our production files where Jenkins will be publishing to. cd / mkdir /webapps/hello_world Our production code will be sitting under this directory, hello_world/ hello_world/ polls/ ... Under apache's enabled site directory, let's create a conf file for our web application. cd /etc/apache2/sites-enabled touch hello_world.conf In hello_world.conf, enter the following contents, Listen 8888 <VirtualHost *:8888> # The ServerName directive sets the request scheme, hostname and port that # the server uses to identify itself. This is used when creating # redirection URLs. In the context of virtual hosts, the ServerName # specifies what hostname must appear in the request's Host: header to # match this virtual host. For the default virtual host (this file) this # value is not decisive as it is used as a last resort host regardless. # However, you must set it for any further virtual host explicitly. #ServerName www.example.com # ServerAdmin webmaster@localhost # DocumentRoot /var/www/html # Available loglevels: trace8, ..., trace1, debug, info, notice, warn, # error, crit, alert, emerg. # It is also possible to configure the loglevel for particular # modules, e.g. # LogLevel info ssl:warn WSGIScriptAlias / /webapps/hello_world/hello_world/wsgi.py WSGIDaemonProcess helloworld.com python-path = /django_hello_world WSGIProcessGroup helloworld.com <Directory> /webapps/hello_world/hello_world> <Files wsgi.py> Require all granted </Files> </Directory> ErrorLog ${ APACHE_LOG_DIR } /error.log CustomLog ${ APACHE_LOG_DIR } /access.log combined # For most configuration files from conf-available/, which are # enabled or disabled at a global level, it is possible to # include a line for only one particular virtual host. For example the # following line enables the CGI configuration for this host only # after it has been globally disabled with \"a2disconf\". #Include conf-available/serve-cgi-bin.conf </VirtualHost> This document tells apache about configurations of our site. Apache will be listening on port 8888 and our site should be accessible on port 8888 at all IP addresses. There is a wsgi.py file we need to create for apache to load the Django application. Go back to our development directory, cd ~/django_hello_world/hello_world cd hello_world touch wsgi.py The file structure should look like this, hello_world/ hello_world/ wsgi.py ... polls/ ... In wsgi.py, enter the following content, import os from django.core.wsgi import get_wsgi_application os . environ . setdefault ( \"DJANGO_SETTINGS_MODULE\" , \"hello_world.settings\" ) application = get_wsgi_application () And that's it, we are set for apache. Now let's get our code into our production directory. Setup Git Repository Next setup is to setup the git repository and pull code to our production directory. For simplicity, we will setup the git repository as a local directory on our machine. cd / mkdir git_repo cd git_repo git init --bare hello_world.git This will setup a local git repository under /git_repo called hello_world.git. Next, let setup our development code to track this directory and push our code to it. cd /django_hello_world/hello_world git remote add origin /git_repo/hello_world.git Make our first commit by typing, git status git add --all git commit -a Type in our first commit message and finish the commit. Next let's push our first commit to git repository, git push -u origin master This will push our commit to remote called origin and setup our local master to track the remote master branch. Next let's pull our code into our production directory. cd /webapps git clone /git_repo/hello_world.git Our lastest code should show up in the webapps directory. This is also where apache will be accessing our site code. Restart apache server, sudo systemctl restart apache2 Now, we should be able to see the site under 8888 port, try localhost:8888 or 127.0.0.1:8888 in our web browser. Setup Jenkins to Link Everything First thing first, let's install Jenkins. Follow the instructions on the website, https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+Ubuntu . wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add - sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' sudo apt-get update sudo apt-get install jenkins Jenkins need JDK and JRE installed to run, install them first if your machine doesn't have them. After installation, check status of Jenkins and make sure it's running, sudo service jenkins status If Jenkins is not running, start it with, sudo service jenkins start Now, open up browser and go to localhost:8080, this is where Jenkins is served. At first time, Jenkins will ask your to create an admin account, just follow the steps to create the admin account. Create a New Build Configuration At Jenkins's home page, click New Item to create an entry for our project. Enter \"hellow world\" for the item name and select Freestyle project . On the next pages, where are a few tabs we need to go through. Under Source Code Management , select Git . A new sub window will appear. Enter \"/git_repo/hello_world.git\" for Repository URL* . This is where we setup our git repository. Leave Credentials as \"none\" as we don't have authentification to access this repository. Leave Brances to build as \"*/master\". Under Build Triggers , check Build periodically , and enter \"H/10 * * * *\" fpr Schedule , this will check for any changes every 10 minutes. Also check Build when a change is pushed to GitHub , this will trigger Jenkins to run whenever a change checked in. Under Build , this is where we will be entering our build script, type in the following, cd /webapps/hello_world python manage.py migrate python manage.py test --noinput hello_world polls sudo systemctl restart apache2 This is also where we can run our test scripts before make our changes live. Click save and we should be good. In the next page, which is also where our project dash board, click Build Now and once its finished, we can see the latest build result under Build History . Make a Simple Change and See It Becomes Live Let's make a change to our source code and test if our Jenkins does the job. cd ~/django_hello_world/hello_world/polls In the \"views.py\" file, we had the code as following, from django.http import HttpResponse def index ( request ): return HttpResponse ( \"Hello, world. You're at the polls index.\" ) from django.http import HttpResponse def index ( request ): return HttpResponse ( \"Hello, world. You're at the polls index. An update on the polls index from Jenkins\" ) Commit and push the new changes, git commit -a git push Now go to localhost:8888, we should be able to see our change becomes live once Jenkins finish the new build. And that's it, we just setup our first continous integration system.","tags":"Jenkins","title":"Setup Jenkins with Django for Continous Deployment"},{"url":"https://hazelement.github.io/setup-pelican-for-github-user-pages.html","text":"For those who don't know. Github has this Pages utility which allow each user to setup a personal sub-domain under Github, functioning like a personal blog. It uses a unique git repo for each user to server its file content. For details, check out their website, https://pages.github.com . There are two types of Github Pages, Project Pages and User Pages. Setting up Project Pages is straight forward. I will be discussing setting up User Pages and some tricks I used to streamline the publishing process. About Github Pages Files of a Github page reside in a very specific Github repository that is owned and unique to each user. They look like this format, yourname.github.io, where \"yourname\" is your Github name. The repository has to follow this format otherwise, it won't work. Go ahead and create a new repository named yourname.github.io. Once that's setup, you can see it on your Github profile and it is waiting for a init push. Now let's get back to our Pelican project. We don't need to clone it to our local disk. Pushings Pelican Output to Github Repo The idea is basically to push Pelican's output folder to the Github repository we just created. To achive this, we have a great tool called ghp-import . We can install it easily with the following command: pip install ghp-import A normal command using ghp-import is like follows: pelican content -o output -s pelicanconf.py ghp-import output git push git@github.com:username/username.github.io.git gh-pages:master The first line generate all rst documents into our output folder. ghp-import then import this output folder into a git branch called gh-pages. Then the last line push this branch to its remote repository which is our Github User Pages repo, yourname.github.io. gh-pages is our local branch and master is our remote repository branch. Please note that the remote branch must be the master branch for it to work properly. The last command will prompt your enter your username and password. Simply enter that, our output folder should be pushed to the repo successfully. Now open up browser and enter username.github.io and we can see our blog live on the web. Github 2-step Authentification If you have 2-step Authentification setup on Github account, using the git push command might not work for you as it doesn't implement a way for you to enter the second passcode. There are 2 ways to solve this problem, one way is to generate a app hash string passcode from Github and use it while doing git push. It's annoying as we have to keep that somewhere and we need to enter that everytime we perform a push. Another easier way is to generate a ssh and put your public key to github. Github SSH Access There are many tutorials on how to generate a SSH key pair. A SSH key pair contains a private key and a public key. A private key is our personal key and we should alway keep secret. A public key is like a lock that matches our private key. When we need to access some machine remotely, we give public key to remote mahine manager and he can install it to his machine. It's like installing our lock onto his house's front door (in this case, his house would be the machine). So we can get into his house with our prviate key. And of course, he can setup locks that comes from other people, ie his door can have many locks and each lock can open his door. If you are using a linux machine, a quick way to generate a key pair is to use ssh-keygen. ssh-keygen -t rsa -C \"your_email@example.com\" This will generate two files, id_rsa, and id_rsa.pub. Open id_rsa.pub with any text editor and copy its entire content. Now let's put this public key to our Github account so that we can use our private key to access Github. In https://github.com/settings/keys , we have a section to add new public key. Paste everything from public key into \"Key\" section and name \"title\" to \"mySSHKey\". And click on add SSH key. We should be good to go. Next time when we do a git push, it should stop asking us about our password. Streamline With A Script We can stream line the publishing process with a bash script. Let's first go to our project root folder and create a file called pubish. touch publish In this file, let's enter the following content #!/bin/bash pelican content -o output -s pelicanconf.py ghp-import output git push git@github.com:username/username.github.io.git gh-pages:master Making this file executable: chmod +x publish We just created a script to perform the publishing process for us. To publish new content, simply enter this command under project root directory. ./publish It should perform all the task for us.","tags":"Pelican","title":"Setup Pelican for Github User Pages"},{"url":"https://hazelement.github.io/using-pelican-for-blogging.html","text":"Pelican is a popular static website generator written in Python. It saves bloggers from worrying about formats so that they can focus on the content itself. Pelican to bloggers is like Latex to document writters. Pelican take advantage of Markdown and reStructured text (rst) to generated formatted texts. I wrote this website usig rst. Markdown is also a good option as well. Get started Pelican has a great tutorial covering the basic steps to setup a website to play with. http://docs.getpelican.com/en/stable/quickstart.html . Here is a brief summary of that page. Installation To install pelican with pip: pip install pelican If we are using markdown, we can install it with pip too: pip install markdown Create a project A directory must be created for our new project: mkdir -p ~/pelican_tutorial cd pelican_tutorial Once we are in our project directory, we can create a project using the following command: pelican-quickstart Pelican then will ask us a few questions regarding your website. Don't worry if we are not sure on some of these questions, all these options can be changed afterwards. An example of these questions are here: Welcome to pelican-quickstart v3.6.3. This script will help you create a new Pelican-based website. Please answer the following questions so this script can generate the files needed by Pelican. > Where do you want to create your new web site? [ . ] > What will be the title of this web site? my_first_blog > Who will be the author of this web site? haze > What will be the default language of this web site? [ en ] > Do you want to specify a URL prefix? e.g., http://example.com ( Y/n ) n > Do you want to enable article pagination? ( Y/n ) y > How many articles per page do you want? [ 10 ] > What is your time zone? [ Europe/Paris ] > Do you want to generate a Fabfile/Makefile to automate generation and publishing? ( Y/n ) y > Do you want an auto-reload & simpleHTTP script to assist with theme and site development? ( Y/n ) y > Do you want to upload your website using FTP? ( y/N ) n > Do you want to upload your website using SSH? ( y/N ) n > Do you want to upload your website using Dropbox? ( y/N ) n > Do you want to upload your website using S3? ( y/N ) n > Do you want to upload your website using Rackspace Cloud Files? ( y/N ) n > Do you want to upload your website using GitHub Pages? ( y/N ) n Done. Your new project is available at /xxx/pelican_tutorial Create an articles with category Next we are going to create our first post with a category specified. In plelican, each post is a rst file stored within the cotent directory. ~/pelican_tutorial/content Although, categories can be specified within rst file similar to a tag. I prefer to take advantage of folders to put my rst files into each category. In the content folder, if we created folders and put our rst file in each sub folder. Then each folder will be considered as a category. ~/pelican_tutorial/tutorial We just created a tutorial category. And let's create our first post under this category. cd ~/pelican_tutorial/tutorial touch myfirst_tutorial.rst We can then input content to this rst file. For example: My first tutorial ######################## :date: 2016-11-19 11:30 :tags: reStructured text, rst :authors: Haze ===== Title ===== Subtitle -------- This is a paragraph. Save this file, and we are ready to generate our first post into html file. Generate site From site root directory cd ~/pelican_tutorial Run the following code to generate your site: pelican content A folder called output will be generated. This is where our site sits. To see how our site looks like, enter output directory: cd output Run the local pelican server: python -m pelican.server Open up web browser, and type in http://localhost:8000/ , we should see the website served from local directory. Some tips Autosite updates Usually we would like to see our website updates live while we changing the rst file contents, especially during development. This can be achieved by running the following command. make regenerate \"make\" is a script at the project root folder. Don't close terminal after running this command as the script is monitoring our project folder to detect any changes. We can continous editing and saving your rst file. All changes will be reflected on your local website. Althought we need to refresh the page of course. One drawback with this script is that if we have a syntax error in the rst file, it will likely crash the script and we would have to restart it again after fixing the syntax. For popular rst syntax, check out my other post, reStructured Text Syntax . Next up, Setup Pelican for Github User Pages .","tags":"Pelican","title":"Using Pelican for Blogging"},{"url":"https://hazelement.github.io/restructured-text-syntax.html","text":"A page with popular reStructured Text Syntax A page with popular reStructured Text Syntax A page with popular reStructured Text Syntax Title Subtitle This is a paragraph. Paragraphs line up at their left edges, and are normally separated by blank lines. Plain text Typical result This is a normal text paragraph. The next paragraph is a code sample: It is not processed in any way, except that the indentation is removed. It can span multiple lines. This is a normal text paragraph again. Bullet lists: This is item 1 This is item 2 Bullets are \"-\", \"*\" or \"+\". Continuing text must be aligned after the bullet and whitespace. Note that a blank line is required before the first item and after the last, but is optional between items. Enumerated lists: This is the first item This is the second item Enumerators are arabic numbers, single letters, or roman numerals List items should be sequentially numbered, but need not start at 1 (although not all formatters will honour the first index). This item is auto-enumerated Definition lists: what Definition lists associate a term with a definition. how The term is a one-line phrase, and the definition is one or more paragraphs or body elements, indented relative to the term. Blank lines are not allowed between term and definition. Authors: Tony J. (Tibs) Ibbs, David Goodger (and sundry other good-natured folks) Version: 1.0 of 2001/08/08 Dedication: To my father. A paragraph containing only two colons indicates that the following indented or quoted text is a literal block. Whitespace, newlines, blank lines, and all kinds of markup (like *this* or \\this) is preserved by literal blocks. The paragraph containing only '::' will be omitted from the result. The :: may be tacked onto the very end of any paragraph. The :: will be omitted if it is preceded by whitespace. The :: will be converted to a single colon if preceded by text, like this: It's very convenient to use this form. Literal blocks end when text returns to the preceding paragraph's indentation. This means that something like this is possible: We start here and continue here and end here. Per-line quoting can also be used on unindented literal blocks: > Useful for quotes from email and > for Haskell literate programming. Grid table: Header 1 Header 2 Header 3 body row 1 column 2 column 3 body row 2 Cells may span columns. body row 3 Cells may span rows. Cells contain blocks. body row 4 Simple table: Inputs Output A B A or B False False False True False True False True True True True True External hyperlinks, like Python . Internal crossreferences, like example .","tags":"reStructuredText","title":"reStructured Text Syntax"}]}